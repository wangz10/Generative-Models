{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os, sys, json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance as dist\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, manifold, decomposition, random_projection, neighbors, metrics, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk', font_scale=1.2)\n",
    "from IPython import display\n",
    "np.random.seed(2018)\n",
    "tf.set_random_seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print (mnist.train.num_examples)\n",
    "print (mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (10000, 784)\n",
      "(55000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = mnist.train.images, mnist.test.images\n",
    "print (X_train.shape, X_test.shape)\n",
    "labels_train = mnist.train.labels\n",
    "n_samples = int(mnist.train.num_examples)\n",
    "print (labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9198\n"
     ]
    }
   ],
   "source": [
    "# A simple Logistic Regression model to classify the digits\n",
    "logit = linear_model.LogisticRegression()\n",
    "logit.fit(X_train, labels_train)\n",
    "print(metrics.accuracy_score(mnist.test.labels, logit.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder_models.VariationalAutoencoder import VariationalAutoencoder\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "learning_rate=0.001\n",
    "\n",
    "# VAE architecture: 784 -> 500 -> 500 -> 2 -> 500 -> 500 -> 784\n",
    "vae2d = VariationalAutoencoder([784, 500, 500, 2], \n",
    "                               learning_rate=learning_rate\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 3047.4703 \n",
      "Epoch 2: loss = 2485.6395 \n",
      "Epoch 3: loss = 2354.7739 \n",
      "Epoch 4: loss = 2268.5700 \n",
      "Epoch 5: loss = 2197.3673 \n",
      "Epoch 6: loss = 2144.5467 \n",
      "Epoch 7: loss = 2096.2754 \n",
      "Epoch 8: loss = 2055.8172 \n",
      "Epoch 9: loss = 2026.1778 \n",
      "Epoch 10: loss = 2000.8083 \n",
      "Epoch 11: loss = 1978.6501 \n",
      "Epoch 12: loss = 1959.7616 \n",
      "Epoch 13: loss = 1942.7579 \n",
      "Epoch 14: loss = 1929.0888 \n",
      "Epoch 15: loss = 1913.6448 \n",
      "Epoch 16: loss = 1904.3606 \n",
      "Epoch 17: loss = 1892.9023 \n",
      "Epoch 18: loss = 1882.1108 \n",
      "Epoch 19: loss = 1870.5142 \n",
      "Epoch 20: loss = 1865.2764 \n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "        # Fit training using batch data\n",
    "        loss = vae2d.partial_fit(batch_xs)\n",
    "        # Compute average loss\n",
    "        avg_loss += loss / n_samples * batch_size\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch %d: loss = %.4f \"% (epoch+1, avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE architecture: 784 -> 500 -> 500 -> 20 -> 500 -> 500 -> 784\n",
    "vae20d = VariationalAutoencoder([784, 500, 500, 20], \n",
    "                               learning_rate=learning_rate\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 2449.0908 \n",
      "Epoch 2: loss = 1146.7827 \n",
      "Epoch 3: loss = 898.0939 \n",
      "Epoch 4: loss = 776.1940 \n",
      "Epoch 5: loss = 708.2477 \n",
      "Epoch 6: loss = 660.1153 \n",
      "Epoch 7: loss = 625.4214 \n",
      "Epoch 8: loss = 596.4360 \n",
      "Epoch 9: loss = 572.2996 \n",
      "Epoch 10: loss = 553.3875 \n",
      "Epoch 11: loss = 536.0296 \n",
      "Epoch 12: loss = 520.6217 \n",
      "Epoch 13: loss = 507.4268 \n",
      "Epoch 14: loss = 493.1958 \n",
      "Epoch 15: loss = 483.4196 \n",
      "Epoch 16: loss = 473.3497 \n",
      "Epoch 17: loss = 462.0246 \n",
      "Epoch 18: loss = 454.7900 \n",
      "Epoch 19: loss = 446.3437 \n",
      "Epoch 20: loss = 438.4803 \n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "        # Fit training using batch data\n",
    "        loss = vae20d.partial_fit(batch_xs)\n",
    "        # Compute average loss\n",
    "        avg_loss += loss / n_samples * batch_size\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch %d: loss = %.4f \"% (epoch+1, avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_models/VAE_20d/model.ckpt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae2d.save('trained_models/VAE_2d')\n",
    "vae20d.save('trained_models/VAE_20d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
